{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "eng_stopwords =stopwords.words('english')\n",
    "\n",
    "dataset = pd.read_csv('updated_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(doc):\n",
    "    words = word_tokenize((doc).lower())\n",
    "    words = [wnl.lemmatize(word) for word in words]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    return {word: True for word in words if word not in eng_stopwords and word.isalpha() and word not in string.punctuation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    feature_sets = [(preprocessing(text), label) for text, label in zip(dataset['text'], dataset['label'])]\n",
    "    shuffle(feature_sets)\n",
    "    index = int(len(feature_sets) * 0.85)\n",
    "    train_set, test_set = feature_sets[:index], feature_sets[index:]\n",
    "\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "    print('Accuracy: ', accuracy)\n",
    "\n",
    "    classifier.show_most_informative_features(5)\n",
    "\n",
    "    file = open('model.pickle', 'wb')\n",
    "    pickle.dump(classifier, file)\n",
    "    file.close()\n",
    "\n",
    "    return classifier\n",
    "\n",
    "def readModel():\n",
    "    try:\n",
    "        file = open('model.pickle', 'rb')\n",
    "        classifier = pickle.load(file)\n",
    "        file.close()\n",
    "        return classifier\n",
    "    except:\n",
    "        print(\"Model is not available\")\n",
    "        print(\"Training model...\")\n",
    "        return trainModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeReview():\n",
    "    while True:\n",
    "        review = input(\"Enter review[>=2 words]: \")\n",
    "        words = review.split()\n",
    "\n",
    "        if len(words) >= 2:\n",
    "            print(\"Review added!\")\n",
    "            break\n",
    "        print(\"Review should have atleast 2 words\")\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeReview(review, classifier):\n",
    "    if(len(review) == 0):\n",
    "        print(\"No review found\")\n",
    "        return\n",
    "    words = word_tokenize(review.lower())\n",
    "    words = FreqDist([word for word in words if word.isalpha() and word not in string.punctuation])\n",
    "\n",
    "    tag = pos_tag(words)\n",
    "    print(\"POS tag:\")\n",
    "    for i, word in enumerate(tag):\n",
    "        print(f\"{i + 1}. {word[0]}: {word[1]}\")\n",
    "    \n",
    "    for word in words:\n",
    "        print(f\"Word: {word}\")\n",
    "        print(\"=============================\")\n",
    "\n",
    "        synsets = wordnet.synsets(word)\n",
    "        synonyms = [] # or use set() to avoid duplicates\n",
    "        antonyms = []\n",
    "\n",
    "        for synset in synsets:\n",
    "            for lemma in synset.lemmas():\n",
    "                synonyms.append(lemma.name())\n",
    "                for antonym in lemma.antonyms():\n",
    "                    antonyms.append(antonym.name())\n",
    "\n",
    "        if(len(synonyms) == 0):\n",
    "            print(\"No synonyms found\")\n",
    "        else:\n",
    "            print(\"Synonyms:\")\n",
    "            for syn in synonyms:\n",
    "                print(syn)\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "        if(len(antonyms) == 0):\n",
    "            print(\"No antonyms found\")\n",
    "        else:\n",
    "            print(\"Antonyms:\")\n",
    "            for ant in antonyms:\n",
    "                print(ant)\n",
    "    clean_review = [word for worn in word_tokenize(review.lower()) if word.isalpha() and word not in string.punctuation and word not in eng_stopwords]\n",
    "\n",
    "    result = classifier.classify(FreqDist(clean_review))\n",
    "\n",
    "    print(f\"Review is {result}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Sentiment Analysis\n",
      "Your Review:  No Review\n",
      "Sentiment:  No Sentiment\n",
      "1. Write Review\n",
      "2. Analyze Review\n",
      "3. Exit\n",
      "Review added!\n",
      "Review Sentiment Analysis\n",
      "Your Review:  Very good nice\n",
      "Sentiment:  No Sentiment\n",
      "1. Write Review\n",
      "2. Analyze Review\n",
      "3. Exit\n",
      "POS tag:\n",
      "1. very: RB\n",
      "2. good: JJ\n",
      "3. nice: NN\n",
      "Word: very\n",
      "=============================\n",
      "Synonyms:\n",
      "very\n",
      "identical\n",
      "selfsame\n",
      "very\n",
      "very\n",
      "really\n",
      "real\n",
      "rattling\n",
      "very\n",
      "\n",
      "No antonyms found\n",
      "Word: good\n",
      "=============================\n",
      "Synonyms:\n",
      "good\n",
      "good\n",
      "goodness\n",
      "good\n",
      "goodness\n",
      "commodity\n",
      "trade_good\n",
      "good\n",
      "good\n",
      "full\n",
      "good\n",
      "good\n",
      "estimable\n",
      "good\n",
      "honorable\n",
      "respectable\n",
      "beneficial\n",
      "good\n",
      "good\n",
      "good\n",
      "just\n",
      "upright\n",
      "adept\n",
      "expert\n",
      "good\n",
      "practiced\n",
      "proficient\n",
      "skillful\n",
      "skilful\n",
      "good\n",
      "dear\n",
      "good\n",
      "near\n",
      "dependable\n",
      "good\n",
      "safe\n",
      "secure\n",
      "good\n",
      "right\n",
      "ripe\n",
      "good\n",
      "well\n",
      "effective\n",
      "good\n",
      "in_effect\n",
      "in_force\n",
      "good\n",
      "good\n",
      "serious\n",
      "good\n",
      "sound\n",
      "good\n",
      "salutary\n",
      "good\n",
      "honest\n",
      "good\n",
      "undecomposed\n",
      "unspoiled\n",
      "unspoilt\n",
      "good\n",
      "well\n",
      "good\n",
      "thoroughly\n",
      "soundly\n",
      "good\n",
      "\n",
      "Antonyms:\n",
      "evil\n",
      "evilness\n",
      "bad\n",
      "badness\n",
      "bad\n",
      "evil\n",
      "ill\n",
      "Word: nice\n",
      "=============================\n",
      "Synonyms:\n",
      "Nice\n",
      "nice\n",
      "decent\n",
      "nice\n",
      "nice\n",
      "skillful\n",
      "dainty\n",
      "nice\n",
      "overnice\n",
      "prissy\n",
      "squeamish\n",
      "courteous\n",
      "gracious\n",
      "nice\n",
      "\n",
      "Antonyms:\n",
      "nasty\n",
      "Review is negative\n",
      "Review Sentiment Analysis\n",
      "Your Review:  Very good nice\n",
      "Sentiment:  negative\n",
      "1. Write Review\n",
      "2. Analyze Review\n",
      "3. Exit\n"
     ]
    }
   ],
   "source": [
    "classifier = readModel()\n",
    "\n",
    "review = \"\"\n",
    "sentiment = \"\"\n",
    "\n",
    "while True:\n",
    "    print(\"Review Sentiment Analysis\")\n",
    "    print(\"Your Review: \", \"No Review\" if len(review) == 0 else review)\n",
    "    print(\"Sentiment: \", \"No Sentiment\" if len(sentiment) == 0 else sentiment)\n",
    "    print(\"1. Write Review\")\n",
    "    print(\"2. Analyze Review\")\n",
    "    print(\"3. Exit\")\n",
    "    choice = int(input(\"Enter choice: \"))\n",
    "    if choice == 1:\n",
    "        review = writeReview()\n",
    "    elif choice == 2:\n",
    "        sentiment = analyzeReview(review, classifier)\n",
    "    elif choice == 3:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid choice\")\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
